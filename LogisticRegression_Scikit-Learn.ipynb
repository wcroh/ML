{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KubnO2egumeN"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXR0qyJ-uTpC"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "data = load_digits()\n",
        "print(data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FfgysTkuTpC"
      },
      "source": [
        "print(\"Data: \", data['data'].shape)\n",
        "print(\"Label:\", data['target'].shape)\n",
        "\n",
        "import numpy as np\n",
        "for c in range(10):\n",
        "  print('Class', c, 'Number:', np.sum(data['target']==c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG1dHr4CuTpC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for c in range(10):\n",
        "  i = 0\n",
        "  while(1):\n",
        "    if data['target'][i]==c:\n",
        "      plt.subplot(2,5,c+1)\n",
        "      plt.axis('off')\n",
        "      plt.imshow(data['data'][i].reshape(8,8), cmap = plt.cm.gray_r)\n",
        "      plt.title(c)\n",
        "      break\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeX7JqhuTpD"
      },
      "source": [
        "test_indices, train_indices = [],[]\n",
        "num = [0] * 10 #class counting array\n",
        "for i in range(len(data['target'])):\n",
        "  if num[data['target'][i]] < 20: #test data 뽑는 과정\n",
        "    test_indices.append(i)\n",
        "    num[data['target'][i]] += 1\n",
        "  else:\n",
        "    train_indices.append(i)\n",
        "\n",
        "train_data = data['data'][train_indices]\n",
        "train_target = data['target'][train_indices]\n",
        "\n",
        "test_data = data['data'][test_indices]\n",
        "test_target = data['target'][test_indices]\n",
        "\n",
        "print(test_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie567PVduTpD"
      },
      "source": [
        "train_data23 = train_data[(train_target == 2) | (train_target == 3)]\n",
        "train_target23 = train_target[(train_target == 2) | (train_target == 3)]\n",
        "test_data23 = test_data[(test_target == 2) | (test_target == 3)]\n",
        "test_target23 = test_target[(test_target == 2) | (test_target == 3)]\n",
        "\n",
        "print(test_data23.shape)\n",
        "print(train_data23.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ci9vgU5uTpE"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000, solver='sag') # backprop 안하는 모델\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter= 1000) #backprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etwr4biEuTpE"
      },
      "source": [
        "LR = LogisticRegression(max_iter=1, solver='sag')\n",
        "LR.fit(train_data23, train_target23)\n",
        "\n",
        "train_predict23 = LR.predict(train_data23)\n",
        "test_predict23 = LR.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
        "test_acc23 = np.sum(test_target23 == test_predict23) / len(test_target23)\n",
        "\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6DMzuxRuTpF"
      },
      "source": [
        "NN23 = MLPClassifier(hidden_layer_sizes = (10), activation = 'relu', learning_rate_init = 0.01, max_iter = 1)\n",
        "NN23.fit(train_data23, train_target23)\n",
        "\n",
        "train_predict23 = NN23.predict(train_data23)\n",
        "test_predict23 = NN23.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
        "test_acc23 = np.sum(test_target23 == test_predict23) / len(test_target23)\n",
        "\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGiSsaIKuTpF"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "joblib.dump(NN23, 'models/NN23.joblib') \n",
        "\n",
        "NN23_load = joblib.load('models/NN23.joblib') \n",
        "\n",
        "train_predict23 = NN23_load.predict(train_data23)\n",
        "test_predict23 = NN23_load.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "train_acc23 = np.sum(train_target23 == train_predict23) / len(train_target23)\n",
        "test_acc23= np.sum(test_target23 == test_predict23) / len(test_target23)\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NA25EGYuTpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feccb813-3e0a-4143-a9c2-482af277ac99"
      },
      "source": [
        "NN = MLPClassifier(hidden_layer_sizes = (512, 256, 256), activation = 'relu', learning_rate_init = 0.001, max_iter = 50)\n",
        "NN.fit(train_data, train_target)\n",
        "\n",
        "train_predict = NN.predict(train_data)\n",
        "\n",
        "train_acc = np.sum(train_target == train_predict) / len(train_target)\n",
        "\n",
        "print(\"train_acc :\", train_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQud1OhYuTpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a979eff-b5d8-4df6-8afc-5363f6fe1223"
      },
      "source": [
        "joblib.dump(NN, 'models/NN.joblib') \n",
        "NN_load = joblib.load('models/NN.joblib') \n",
        "\n",
        "test_predict = NN.predict(test_data)\n",
        "test_acc = np.sum(test_target == test_predict) / len(test_target)\n",
        "\n",
        "print(\"test_acc :\", test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc : 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R7BMd5YuTpG"
      },
      "source": [
        "먼저, Hidden layer의 개수, 그리고 unit의 개수가 충분하지 않다고 판단되어 layer 및 unit 개수를 계속 늘려보면서 정확도를 비교. # of layers를 1개, 2개, 3개, 4개 등으로 늘려보았고,  # of units는 16, 32, 64, 128, 256, 512, 1024등으로 바꿔가면서 각 조합별로 10번의 시행.  # of layers는 3개, # of units는 (512, 256, 256)일 때 평균적으로 가장 좋은 정확도를 보임. 두 hyperparameter의 숫자가 너무 클 때, training accuracy는 100%가 나왔지만, validation accuracy는 변동도 크고, 원하는 정확도 만큼 나오지 않았음. training data에 대해 Overfitting이 일어났다고 판단.\n",
        "\n",
        "\n",
        "그 다음, learning rate를 0.1부터 0.01, 0.001, 0.0001 등으로 변화시키면서 시행. (논문을 찾아보니 learning rate를 지수꼴로 다양하게 테스트해보는게 좋다는 언급이 많았음) 여러 번 테스트해보니 시행마다 정확도 차이가 많이 났는데, 0.001일 때 가장 그 차이가 적었고, 정확도 역시 크게 나옴.\n",
        "\n",
        "\n",
        "마지막으로 iteration 횟수를 조절. max_iter 역시 overfitting 및 underfitting에 큰 영향을 주는 요소. 위에서 결정한 hyperparameters로 시행을 돌려보니 training accuracy는 계속해서 100%가 나왔지만, validation accuracy는 95% 정도가 나옴. 따라서, training accuracy가 크게 떨어지지 않는 선에서, max_iter변수를 1000부터 500, 100, 50 등으로 계속 줄여보았음.(Overfitting 방지를 위해) max_iter = 40일 때 가장 좋은 정확도를 계속해서 보여줌.\n",
        "\n",
        "이렇게 # of layers, # of units, learning rate, max_iteration 이 4가지의 hyperparameter tuning을 통해 정확도 0.98을 나타내는 모델을 만듦."
      ]
    }
  ]
}